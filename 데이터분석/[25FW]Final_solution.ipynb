{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c0f44f",
   "metadata": {},
   "source": [
    "빅데이터 분석 기말고사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f374f32",
   "metadata": {},
   "source": [
    "각 문제 아래에 답을 쓰고 실행하여 제출하세요. \n",
    "반드시 3시전까지 업로드하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d8c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cfef412",
   "metadata": {},
   "source": [
    "1. 선형회귀에 대해서 설명하세요. 선형회귀를 경사하강법으로 해결할 때, 손실함수를 어떻게 가정하는지 설명하세요. (10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92cbf0",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfefade",
   "metadata": {},
   "source": [
    "A) 선형회귀는 데이터의 피처와 타겟 변수 사이의 관계를 선형으로 모델링하여, 해당 선형모델링의 계수를 찾음으로써, 그 관계를 찾는 것을 의미한다. 선형회귀를 경사하강법으로 해결할 때 손실함수는 선형모델을 통한 출력값과 실제 타겟 변수 사이의 차이를 바탕으로 가정하는데, 본 수업에서는 제곱합으로 손실함수를 가정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbfd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "571322b3",
   "metadata": {},
   "source": [
    "2. advertising1,2는 가정별 TV,신문,라디오를 이용하는 시간과 Sales 수치를 나타내서, 어떤 매체를 통해 광고하는 것이 효율적인 지를 분석할 수 있는 데이터입니다. 아래 스텝을 따라서 분석하세요. 타겟 변수는 Sales입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f638b",
   "metadata": {},
   "source": [
    "2. (a) advertising1.csv와 advertising2.csv를 판다스의 read_csv를 통해서 load하여  advertising1, advertising2의 이름으로 할당하세요. 또한 두 데이터를 advertising의 이름으로 병합하세요, 병합 시에 ignore_index 옵션을 활용하여, index가 0~199까지 되게 하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009832f5",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91251c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3   12.0\n",
       "3    151.5   41.3       58.5   16.5\n",
       "4    180.8   10.8       58.4   17.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1   14.0\n",
       "197  177.0    9.3        6.4   14.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   18.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "advertising1=pd.read_csv(\"advertising/advertising1.csv\")\n",
    "advertising2=pd.read_csv(\"advertising/advertising2.csv\")\n",
    "advertising=pd.concat([advertising1,advertising2],ignore_index=True)\n",
    "advertising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f89b3",
   "metadata": {},
   "source": [
    "2. (b) advertising 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 분할하되 3:1:1 의 비율로 분할 하세요. (random_state는 1234로 하세요.) (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe07b2",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02b16680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(advertising.drop(columns='Sales'), \n",
    "                                                    advertising.Sales,\n",
    "                                                    test_size=0.2, random_state=1234)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fed10",
   "metadata": {},
   "source": [
    "2. (c) 훈련데이터의 분포를 바탕으로, 훈련데이터, 검증데이터, 테스트데이터에 표준 정규화를 적용하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8e51f",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76fe0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_val = scaler.transform(X_val)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44506b0c",
   "metadata": {},
   "source": [
    "2. (d) 준비된 데이터 셋에 대해 SGDRegressor를 활용하여 경사하강법을 통한 선형회귀를 수행하고자 합니다. 이 때 아래의 학습률 후보군 및 학습률 스케쥴링 전략 중에서 MAE가 가장 낮은 학습률 및 스케쥴링 전략을 찾아서 프린트하세요. 또한 해당 학습률과 스케쥴링 전략으로 훈련시켰을 때 각 피처별 계수를 찾으세요. (절편, 정규화는 사용하지 않으며 최대 반복수는 10000으로 설정합니다. 또한 random_state는 1234로 하세요. GridSearchCV는 사용하지 않습니다.) (10pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18ba035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rate=[1e-4,1e-3,1e-2,1e-1]\n",
    "list_scheduling=['constant','invscaling']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12480b63",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e7faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 invscaling\n",
      "[4.37678034 0.44568746 0.04916637]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np \n",
    "best_MAE=1000\n",
    "best_rate=0\n",
    "best_scheduling='constant'\n",
    "for eta0 in list_rate:\n",
    "    for learning_rate in list_scheduling:\n",
    "        reg = SGDRegressor(fit_intercept=False, penalty=None, max_iter=10000, learning_rate=learning_rate, eta0=eta0, random_state=1234)\n",
    "        reg = reg.fit(X_train, y_train)\n",
    "        y_pred = reg.predict(X_val)\n",
    "        if best_MAE > np.abs(y_pred - y_val).mean():\n",
    "            best_rate=eta0\n",
    "            best_scheduling=learning_rate\n",
    "\n",
    "reg = SGDRegressor(fit_intercept=False, penalty=None, max_iter=10000, learning_rate=best_scheduling, eta0=best_rate, random_state=1234)\n",
    "reg = reg.fit(X_train, y_train)\n",
    "print(best_rate, best_scheduling)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6329b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87cdb414",
   "metadata": {},
   "source": [
    "3. 머신러닝 모델의 과대적합과 과소적합에 대해 설명하고, 이와 연관지어서 라쏘회귀와 릿지회귀에 대해 설명하세요. (10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075005b",
   "metadata": {},
   "source": [
    "답) 과대적합은 학습데이터의 수에 비해 모델이 복잡한 경우를 포함하여, 학습데이터에 대해 과하게 학습되는 경우를 의미한다. 이로 인해 그 결과는 편향이 낮고 분산이 크며, 일반화 능력이 떨어진다. 과소적합은 그 반대로, 모델이 너무 단순하거나 학습이 충분히 되지 않아서 학습데이터에 대해 잘 학습하지 못하는 경우를 의미한다. 이에 따라 편향이 크고 분산이 낮다. 모델 학습의 대표적인 문제는 과대적합이고, 라쏘회귀와 릿지회귀는 이를 해결하기 위해 선형회귀에서 정규화 항을 추가한다. 해당 정규화 항은 모델의 계수의 크기 및 계수 별 분산을 낮추고자 하며 L1 놈 기반의 정규화항인 경우에 라쏘회귀, L2 놈 기반의 정규화 항인 경우에는 릿지회귀라고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbffd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b528b4",
   "metadata": {},
   "source": [
    "4. 타이타닉 데이터는 각 승객별 여러가지 피처와 생존 여부 (타깃변수)를 나타내는 데이터입니다. 함께 첨부한 titanic1.csv~titanic4.csv 파일을 바탕으로 로지스틱회귀를 하고자 합니다. 아래 문제를 해결하세요.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63cdbb",
   "metadata": {},
   "source": [
    "4. (a) 데이터 준비 및 병합을 수행하세요. 각 파일에서 로드한 데이터프레임을 잘 관찰하여, 최종적으로 891개의 데이터에 대해 12개의 피처(타변수 포함)를 갖도록 병합하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33dd752",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d25d55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic1=pd.read_csv(\"titanic/titanic1.csv\")\n",
    "titanic2=pd.read_csv(\"titanic/titanic2.csv\")\n",
    "titanic3=pd.read_csv(\"titanic/titanic3.csv\")\n",
    "titanic4=pd.read_csv(\"titanic/titanic4.csv\")\n",
    "\n",
    "titanic_12=pd.concat([titanic1,titanic2],ignore_index=True)\n",
    "titanic_34=pd.concat([titanic3,titanic4],ignore_index=True)\n",
    "titanic=pd.merge(titanic_12,titanic_34,on=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682fbda",
   "metadata": {},
   "source": [
    "4. (b) 데이터 프레임에서 Pclass, Sex, Age, SibSp, Embarked만을 남겨서 X로, Survived만을 y로 따로 저장하세요. 또한 Sex 피처에서 male은 1, female은 0으로, Embarked에서 S는 0, C는 1, Q는 2로 변환하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf8a0a",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dcb616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=titanic.reindex(['Pclass','Sex','Age','SibSp','Embarked'],axis=1)\n",
    "y=titanic.Survived\n",
    "X['Sex']=X['Sex'].map({'male':1,\"female\":0})\n",
    "X['Embarked']=X['Embarked'].map({'S':0,'C':1, 'Q':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e501d3",
   "metadata": {},
   "source": [
    "4. (c) 훈련 데이터와 테스트 데이터를 3:1의 비율로 분할하세요. (random_state는 1234로 하세요.) (5pt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8a3f4",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c372dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff9869",
   "metadata": {},
   "source": [
    "4. (d) GridSearchCV를 통해, 로지스틱회귀 수행시에 최적의 정규화계수 (C)를 튜닝하고자 합니다. 아래 후보군 주에서 최적의 정규화계수를 찾아서 출력하세요. (결측치처리 객체, 표준정규화 객체를 로지스틱회귀 전에 수행해야 하며, 4-fold 교차검증을 활용합니다.) (로지스틱회귀는 L2정규화를 수행하고 최대 반복수는 10000, solver는 'sag'로 하세요.) (k-fold의 random_state는 1234로 하세요.) (10pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77cc0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_C=[0.0001, 0.001, 0.01, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4cb27",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f740f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 정규화 계수: 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',StandardScaler()),('basemodel',LogisticRegression( solver='sag', penalty='l2', max_iter=10000))])\n",
    "param_grid={'basemodel__C':l_C}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234)  \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 정규화 계수:',grid_search.best_params_['basemodel__C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea7711",
   "metadata": {},
   "source": [
    "4. (e) 학습된 모델에 대해 테스트데이터 셋으로 실험하였을 때, 생존에 대한 재현율은 몇입니까? (코드를 작성하고 출력된 결과를 보고 답하세요.) (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b53378",
   "metadata": {},
   "source": [
    "답) 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       132\n",
      "           1       0.89      0.62      0.73        91\n",
      "\n",
      "    accuracy                           0.81       223\n",
      "   macro avg       0.84      0.78      0.79       223\n",
      "weighted avg       0.83      0.81      0.80       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a49ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b31847c",
   "metadata": {},
   "source": [
    "5. 의사결정트리에 관해서 설명하세요. 구체적으로, (a) 의사결정트리의 노드의 정의, (b) 불순도를 통한 학습원리의 설명, (c) 태스크가 분류/회귀 일때 테스트 데이터에 대한 예측 방법을 설명하세요. (10pt) (각각 3pt, 다 맞으면 10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ed877",
   "metadata": {},
   "source": [
    "답) a) 의사결정트리는 각 노드들은 분할 속성을 바탕으로 한 분할 기준이다. (b) 여러 학습방법이 있지만, 기본적으로 노드를 통해 분할된 그룹의 불순도가 낮아지도록 한다. (c) 태스크가 분류일 때는 리프노드에 속한 데이터들의 타깃변수 중 가장 많은 레이블, 회귀일때는 평균으로 예측. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10434ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0bb8b15",
   "metadata": {},
   "source": [
    "6. 보스턴 집값 데이터는 집값과 관련된 여러가지 피처와, 보스턴의 집값을 나타내는 데이터입니다. 보스턴 집값 데이터 (boston.csv)를 분석하고 하는데, 여러 모델들에 대해 각각 하이퍼 파라미터 튜닝 및 성능 비교를 하고자 합니다. (타깃 변수는 MEDV 입니다.) 아래 질문에 대해 답하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af32b97",
   "metadata": {},
   "source": [
    "6. (a) 데이터 셋을 로드하고, 학습 데이터와 테스트 데이터 셋을 3:1의 비율로 분할 하세요. random_state는 1234로 하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba8365",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58a4974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "boston=pd.read_csv(\"boston/boston.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.drop(columns=\"MEDV\"), \n",
    "                                                    boston.MEDV,\n",
    "                                                    test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a5459",
   "metadata": {},
   "source": [
    "6. (b) 선형회귀, 라쏘회귀, 릿지회귀 기법을 통해, boston 데이터셋에 대해 최적의 하이퍼파라미터를 튜닝하고자 합니다. 선형회귀는 아래 리스트 중 l_linear로 시작하는 리스트를 후보군으로, 학습율과 학습율 스케쥴링 방법을 튜닝합니다. 라쏘회귀와 릿지회귀는 l_lasso, l_ridge로 시작하는 리스트를 후보군으로 학습율과 정규화 계수를 튜닝합니다. GridSearchCV를 활용하되, 결측치처리 객체, 최소최대정규화 객체를 회귀 전에 수행해야 하며, 4-fold 교차검증을 활용합니다. (최대 반복수는 10000으로 하고 k-fold 및 회귀객체의 random_state는 1234로 하세요.) 각 기법별로 최적의 하이퍼파라미터를 출력하세요. (10pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89ecd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_linear_rate=[1e-4,1e-3,1e-2,1e-1]\n",
    "l_linear_scheduling=['constant','invscaling']\n",
    "l_lasso_rate=[1e-4,1e-3,1e-2,1e-1]\n",
    "l_lasso_reg=[1e-4,1e-3,1e-2,1e-1]\n",
    "l_ridge_rate=[1e-4,1e-3,1e-2,1e-1]\n",
    "l_ridge_reg=[1e-4,1e-3,1e-2,1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04eab177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 선형회귀 학습율: 0.1\n",
      "최적 선형회귀 스케쥴링: invscaling\n",
      "최적 라쏘 학습율: 0.1\n",
      "최적 라쏘 정규화계수: 0.0001\n",
      "최적 릿지 학습율: 0.1\n",
      "최적 릿지 정규화계수: 0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "R2_scores=[]\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',SGDRegressor(penalty=None, max_iter=10000, random_state=1234))])\n",
    "param_grid={'basemodel__eta0':l_linear_rate,'basemodel__learning_rate':l_linear_scheduling}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234)  \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 선형회귀 학습율:',grid_search.best_params_['basemodel__eta0'])\n",
    "print('최적 선형회귀 스케쥴링:',grid_search.best_params_['basemodel__learning_rate'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',SGDRegressor(penalty='l1', max_iter=10000, random_state=1234))])\n",
    "param_grid={'basemodel__eta0':l_lasso_rate,'basemodel__alpha':l_lasso_reg}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234)  \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 라쏘 학습율:',grid_search.best_params_['basemodel__eta0'])\n",
    "print('최적 라쏘 정규화계수:',grid_search.best_params_['basemodel__alpha'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',SGDRegressor(penalty='l2', max_iter=10000, random_state=1234))])\n",
    "param_grid={'basemodel__eta0':l_ridge_rate,'basemodel__alpha':l_ridge_reg}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234)  \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 릿지 학습율:',grid_search.best_params_['basemodel__eta0'])\n",
    "print('최적 릿지 정규화계수:',grid_search.best_params_['basemodel__alpha'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7dda5d",
   "metadata": {},
   "source": [
    "6. (c) 의사결정트리, 랜덤포레스트, 그래디언트부스팅 기법을 통해, boston 데이터셋에 대해 최적의 계수를 튜닝하고자 합니다. 의사결정트리는 아래 리스트 중 l_decision 리스트를 후보군으로, 트리의 최대깊이를 튜닝합니다. 랜덤포레스트와 그래디언트 부스팅는 각각 l_RF, l_GBT로 시작하는 리스트를 후보군으로 트리 개수와, 피처배깅 하이퍼파라미터를 튜닝합니다. GridSearchCV를 활용하되, 결측치처리 객체, 최소최대정규화 객체를 회귀 전에 수행해야 하며, 4-fold 교차검증을 활용합니다. (k-fold 및 회귀객체의 random_state는 1234로 하세요.) (10pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c215a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l_decision=max_depths = [None, 1,2,3,4,5,6]\n",
    "l_RF_trees=list(np.arange(50,160,20))\n",
    "l_RF_featurebagging=['sqrt','log2']\n",
    "l_GBT_trees=list(np.arange(50,160,20))\n",
    "l_GBT_featurebagging=['sqrt','log2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a8839",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c41936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 의사결정트리 트리 깊이: 6\n",
      "최적 랜덤포레스트 트리 개수: 50\n",
      "최적 랜덤포레스트 피처배깅: sqrt\n",
      "최적 GBT 트리 개수: 130\n",
      "최적 GBT 피처배깅: sqrt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',DecisionTreeRegressor(random_state=1234))])\n",
    "param_grid={'basemodel__max_depth':l_decision}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234) \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 의사결정트리 트리 깊이:',grid_search.best_params_['basemodel__max_depth'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',RandomForestRegressor(random_state=1234))])\n",
    "param_grid={'basemodel__max_features':l_RF_featurebagging, 'basemodel__n_estimators':l_RF_trees}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234) \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 랜덤포레스트 트리 개수:',grid_search.best_params_['basemodel__n_estimators'])\n",
    "print('최적 랜덤포레스트 피처배깅:',grid_search.best_params_['basemodel__max_features'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))\n",
    "\n",
    "\n",
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',MinMaxScaler()),('basemodel',GradientBoostingRegressor(random_state=1234))])\n",
    "param_grid={'basemodel__max_features':l_GBT_featurebagging, 'basemodel__n_estimators':l_GBT_trees}\n",
    "kfold=KFold(n_splits=4, shuffle=True, random_state=1234) \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 GBT 트리 개수:',grid_search.best_params_['basemodel__n_estimators'])\n",
    "print('최적 GBT 피처배깅:',grid_search.best_params_['basemodel__max_features'])\n",
    "R2_scores.append(grid_search.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebbf4f",
   "metadata": {},
   "source": [
    "6. (d) 위에서 얻은 최적의 하이퍼파라미터로 훈련된 6가지 모델로 얻은, 테스트 데이터셋에 대한 R2스코어를 출력하세요. ((c)와 (d) 코드를 수정하여 답을 얻어도 됩니다.) (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984c4fe",
   "metadata": {},
   "source": [
    "답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "071d79fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7646370952964172,\n",
       " 0.7646289962595585,\n",
       " 0.7597872694576642,\n",
       " 0.8518423744849575,\n",
       " 0.8912183412671995,\n",
       " 0.8983824841966818]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2bac2",
   "metadata": {},
   "source": [
    "7. 랜덤포레스트 모델에서 oob 스코어에 대해 설명하세요. (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ba6e3",
   "metadata": {},
   "source": [
    "답) 샘플 배깅시에 선택되지 않는 샘플들이 존재하고 이를 out-of-bagging (oob) 샘플이라고 부른다. 따로 테스트 데이터셋으로 측정한 성능이 아니라, 샘플 배깅 시에 자연히 생기는 이 oob 샘플로 측정한 성능을 oob 스코어라고 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9b082",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
