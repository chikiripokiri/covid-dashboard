{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571322b3",
   "metadata": {},
   "source": [
    "## 1. advertising1,2는 가정별 TV,신문,라디오를 이용하는 시간과 Sales 수치를 나타내서, 어떤 매체를 통해 광고하는 것이 효율적인 지를 분석할 수 있는 데이터입니다. 아래 스텝을 따라서 분석하세요. 타겟 변수는 Sales입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f638b",
   "metadata": {},
   "source": [
    "### 1. (a) advertising1.csv와 advertising2.csv를 판다스의 read_csv를 통해서 load하여  advertising1, advertising2의 이름으로 할당하세요. 또한 두 데이터를 advertising의 이름으로 병합하세요, 병합 시에 ignore_index 옵션을 활용하여, index가 0~199까지 되게 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91251c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3   12.0\n",
       "3    151.5   41.3       58.5   16.5\n",
       "4    180.8   10.8       58.4   17.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1   14.0\n",
       "197  177.0    9.3        6.4   14.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   18.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "advertising1=pd.read_csv(\"advertising/advertising1.csv\")\n",
    "advertising2=pd.read_csv(\"advertising/advertising2.csv\")\n",
    "advertising=pd.concat([advertising1,advertising2],ignore_index=True)\n",
    "advertising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f89b3",
   "metadata": {},
   "source": [
    "### 1. (b) advertising 데이터를 훈련 데이터와 테스트 데이터로 분할하되 4:1의 비율로 분할 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02b16680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(advertising.drop(columns='Sales'), \n",
    "                                                    advertising.Sales,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fed10",
   "metadata": {},
   "source": [
    "### 1.(c) 훈련데이터의 분포를 바탕으로, 훈련데이터와 테스트데이터에 MinMaxScaler를 적용하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44506b0c",
   "metadata": {},
   "source": [
    "### 1.(d) SGDRegressor를 활용하여 경사하강법을 통한 선형회귀를 수행하고 각 피처별 계수를 찾으세요. (절편, 정규화는 사용하지 않으며 최대 반복수는 10000으로 설정합니다. 초기 학습률은 1e-3이며 이 값이 변하지 않도록 합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.14524073  8.57176038  4.30403014]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor(fit_intercept=False, penalty=None, max_iter=10000, learning_rate='constant', eta0=1e-3)\n",
    "reg = reg.fit(X_train, y_train)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3044d",
   "metadata": {},
   "source": [
    "### 1.(e) 어떤 매체가 가장 효과적이라고 할 수 있습니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95970a",
   "metadata": {},
   "source": [
    "#### 답) 각 피처에 최소최대 스케일링을 적용하였음에도, 19.33으로 가장 높은 계수를 갖으므로 TV가 가장 효과적이라고 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf6b9a",
   "metadata": {},
   "source": [
    "### 1.(f) 테스트 데이터의 MAE (Mean Absolute Error) 를 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2391a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 MAE: 2.1547600845356296\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = reg.predict(X_test)\n",
    "print('테스트 데이터셋 MAE:',np.abs(y_pred - y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6329b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12f2450",
   "metadata": {},
   "source": [
    "## 2. 보스턴 집값 데이터는 집값과 관련된 여러가지 피처와, 보스턴의 집값을 나타내는 데이터입니다. 아래 스텝에 따라 보스턴 집값 데이터 (boston.csv) 를 분석하세요. 타깃 변수는 MEDV 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2cec30",
   "metadata": {},
   "source": [
    "### 2. (a) boston 데이터를 로드하고 훈련 데이터와 테스트 데이터를 3:1의 비율로 분할 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c0ceacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston=pd.read_csv(\"boston/boston.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.drop(columns=\"MEDV\"), \n",
    "                                                    boston.MEDV,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd1199",
   "metadata": {},
   "source": [
    "### 2.(b) 훈련데이터의 분포를 바탕으로, 훈련데이터와 테스트데이터에 StandardScaler를 적용하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab6ac7",
   "metadata": {},
   "source": [
    "### 2.(c) SGDRegressor를 활용하여 경사하강법을 통한 릿지회귀를 수행하고 테스트 데이터셋에 대해 MAE를 계산하세요. (최대 학습 반복수는 10000, 정규화 계수는 0.01, 초기 학습률은 1e-4, 학습률 스케쥴링은 invscaling으로 하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b91e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 MAE: 3.531355936925672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "reg = SGDRegressor(penalty='l2', alpha=0.01, max_iter=10000, learning_rate='invscaling', eta0=1e-4)\n",
    "reg = reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print('테스트 데이터셋 MAE:',np.abs(y_pred - y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a1bb6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495    23.1\n",
       "491    13.6\n",
       "385     7.2\n",
       "430    14.5\n",
       "100    27.5\n",
       "       ... \n",
       "489     7.0\n",
       "32     13.2\n",
       "357    21.7\n",
       "283    50.0\n",
       "401     7.2\n",
       "Name: MEDV, Length: 127, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd4dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe15236",
   "metadata": {},
   "source": [
    "## 3. 타이타닉 데이터는 각 승객별 여러가지 피처와 생존 여부 (타깃변수)를 나타내는 데이터입니다. 함께 첨부한 titanic1.csv~titanic4.csv 파일을 바탕으로 아래 문제를 해결하세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e382cf",
   "metadata": {},
   "source": [
    "### 3. (a) 데이터 준비 및 병합을 수행하세요. 각 파일에서 로드한 데이터프레임을 잘 관찰하여, 최종적으로 891개의 데이터에 대해 12개의 피처(타긱변수 포함)를 갖도록 병합하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34aa02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic1=pd.read_csv(\"titanic/titanic1.csv\")\n",
    "titanic2=pd.read_csv(\"titanic/titanic2.csv\")\n",
    "titanic3=pd.read_csv(\"titanic/titanic3.csv\")\n",
    "titanic4=pd.read_csv(\"titanic/titanic4.csv\")\n",
    "\n",
    "titanic_12=pd.concat([titanic1,titanic2],ignore_index=True)\n",
    "titanic_34=pd.concat([titanic3,titanic4],ignore_index=True)\n",
    "titanic=pd.merge(titanic_12,titanic_34,on=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89670042",
   "metadata": {},
   "source": [
    "### 3. (b) 데이터 프레임에서 Pclass, Sex, Age, SibSp, Embarked만을 남겨서 X로, Survived만을 y로 따로 저장하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1362f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=titanic.reindex(['Pclass','Sex','Age','SibSp','Embarked'],axis=1)\n",
    "y=titanic.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b630d",
   "metadata": {},
   "source": [
    "### 3. (c) Sex 피처에서 male은 1, female은 0으로, Embarked에서 S는 0, C는 1, Q는 2로 변환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e5153ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Sex']=X['Sex'].map({'male':1,\"female\":0})\n",
    "X['Embarked']=X['Embarked'].map({'S':0,'C':1, 'Q':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa36588",
   "metadata": {},
   "source": [
    "### 3.(d) 훈련 데이터와 테스트 데이터를 3:1의 비율로 분할 하고, SimpleImputer를 활용하여 훈련 데이터의 각 피처의 평균으로 결측치를 채우세요. (훈련 데이터 및 테스트 데이터 둘다 결측치를 채우세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7cd3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.25)\n",
    "imputer=SimpleImputer()\n",
    "imputer.fit(X_train)\n",
    "X_train=imputer.transform(X_train)\n",
    "X_test=imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf9360",
   "metadata": {},
   "source": [
    "### 3. (e) LogisticRegression을 활용하여 로지스틱 회귀 분류기를 학습하세요. (L2정규화를 수행하고, 정규화계수는 10, 최대 반복수는 10000, solver는 'sag'를 활용하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5055dbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=10000, multi_class=&#x27;multinomial&#x27;,\n",
       "                   solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=10000, multi_class=&#x27;multinomial&#x27;,\n",
       "                   solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                   solver='sag')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression( solver='sag', penalty='l2', C=10, max_iter=10000, multi_class='multinomial')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression( solver='sag', penalty='l2', C=0.1, max_iter=10000, multi_class='multinomial')  ## 정규화 계수를 람다로 이해한경우, C가 0.1이 됨 (시험때는 구체적으로 명시하겠음)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbb3dd",
   "metadata": {},
   "source": [
    "### 3.(f) classification_report를 활용하여 분류 성능을 나타내세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dbdc7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       142\n",
      "           1       0.83      0.77      0.79        81\n",
      "\n",
      "    accuracy                           0.86       223\n",
      "   macro avg       0.85      0.84      0.84       223\n",
      "weighted avg       0.86      0.86      0.86       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da250f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0bb8b15",
   "metadata": {},
   "source": [
    "## 4. 보스턴 집값 데이터 (boston.csv) 를 다시 한번 활용해서 분석하고자 합니다. 아래 질문들에 답하세요. \n",
    "### - 타깃 피처 (집값)은 MEDV입니다.\n",
    "### - 중요한 파라미터/함수 이외의 파라미터/함수들은 자유롭게 선택해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8f3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0929bbbf",
   "metadata": {},
   "source": [
    "### 4. (a) 데이터 로드 및 훈련/테스트 데이터 셋 분할을 수행하세요. (테스트 데이터셋은 20%의 비율로 설정하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8d8af2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "boston=pd.read_csv(\"boston/boston.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.drop(columns=\"MEDV\"), \n",
    "                                                    boston.MEDV,\n",
    "                                                    test_size=0.2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4249b2",
   "metadata": {},
   "source": [
    "### 4. (b) 결측치 처리 변환 객체 (SimpleImputer), 표준스케일링 객체 (StandardScaler), 릿지회귀 객체로 이루어진 파이프라인 객체를 생성하세요. (릿지회귀 객체의 최대 경사하강 반복수는 10000으로 하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c659f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline(steps=[('imputer',SimpleImputer()),('scaler',StandardScaler()),('basemodel',SGDRegressor(penalty='l2', max_iter=10000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32662466",
   "metadata": {},
   "source": [
    "### 4. (c) 러닝레이트 (eta0) 및 정규화 계수 (alpha)에 대해 교차검증 기반 하이퍼파라미터 튜닝을 통해, 최적의 러닝레이트 및 정규화 계수를 알아내세요. (하이퍼 파라미터 후보군은 아래와 같이 주어져있으며, 교차검증은 4-fold를 수행하세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25d9aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_eta0=[0.0001, 0.001, 0.01, 0.1] \n",
    "l_alpha=[0.0001, 0.001, 0.01, 0.1 ,1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "14a8190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 러닝레이트: 0.01\n",
      "최적 정규화 계수: 0.01\n"
     ]
    }
   ],
   "source": [
    "param_grid={'basemodel__alpha':l_alpha, 'basemodel__eta0':l_eta0}\n",
    "kfold=KFold(n_splits=4, shuffle=True)  \n",
    "grid_search=GridSearchCV(pipeline, param_grid=param_grid, cv=kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('최적 러닝레이트:',grid_search.best_params_['basemodel__eta0'])\n",
    "print('최적 정규화 계수:',grid_search.best_params_['basemodel__alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54c770",
   "metadata": {},
   "source": [
    "### 4. (d) 테스트 데이터셋에 대해 MAE 성능을 나타내세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7196d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1433135293256567\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = grid_search.predict(X_test)\n",
    "print(np.abs(y_test-y_pred_test).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
